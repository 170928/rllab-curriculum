{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Policy Implementation.\n",
    "\n",
    "## Plan the changes\n",
    "\n",
    "I will try not to modify the env and concentrate all the changes in the policy and in the algorithm. There are 2 major changes to execute:\n",
    "- Inside the policy (`s_mlp_policy.py`): change the policy representation to accomodate the new latent inputs/units. Then change the `get_action` method so that it also samples from latents and return the observed latent.\n",
    "- In the algorithm (`npo_snn.py`): declare `latent_var`, change the `surr_obj` and `logli`. The first and last thing will also be included in the previous class.\n",
    "In the future the latent variables distribution will also depend on the parameters and the observations. This again will need a change in the `surr_obj`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes executed\n",
    "In the algorithm file:\n",
    "1. a) Declare the symbolic latent var :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_var = self.policy.latent_space.new_tensor_variable(\n",
    "    'latent',\n",
    "    extra_dims=1 + is_recurrent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. b) define the method in policy (see it's not in env, which is not supposed to know about latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def latent_space(self):\n",
    "    return Box(low= -np.inf, high=np.inf, shape=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. (it's of course not doing anything). We need to get the sampled latents to `optimize_policy` where the surr_loss will use them. For this, let's try to put this latent variables in `samples_data`. Let's put it empty, just to make sure the placeholder compiles through correctly.\n",
    "- `samples_data` comes form `process_samples(itr,path)`. I have to change that one anyways to concatenate the latent var sampled from every path into the shape needed for the tensor operations.\n",
    "- Inside `process_samples`: copy exactly everything done for \"actions\". Still should modify `agent_infos` for entropy calculation!! FOR LATER\n",
    "- make `path` come with `\"latents\"`: go to `obtain_samples(itr)`, which calls `rllab.sampler.parallel_sampler.sample_paths`. This in turn sets all the workers to have the same parameters with `singleton_pool.run_each(..set_pol_para...)` and then makes them do the rollouts with `singleton_pool.run_collect(_worker_collect_one_path,...)`. Let's look at the function that collects the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _worker_collect_one_path(G, max_path_length):\n",
    "    path = rollout(G.env, G.policy, max_path_length)\n",
    "    return path, len(path[\"rewards\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `G` comes from the `train()` function, where it gets `env, policy`. We don't need to look at `singleton_pool` in `sample.stateful_pool`, just concentrate in having rollout properly in `rllab.sampler.utils`. BACKDOOR!! Put everything in agent_info: `a, agent_info = agent.get_action(o)`!!!\n",
    "It does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent_infos.append(agent_info)  ##for every step it appends to the list the new dict. All dicts have the same keys\n",
    "...\n",
    "return dict(...\n",
    "    agent_infos=tensor_utils.stack_tensor_dict_list(agent_infos), ## returns a dict with a single list with all step concatenated\n",
    "...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we only need to change `get_action` from the policy! Now revisit what we were saying above: let's keep `process_samples` untouched and simply unpack `\"latent\"` in the same place we unpack `\"mean\"` and `\"log_std\"`. This means the following modifications, different from the ones proposed above:\n",
    "- `init_opt`: I think it's better to still define the latent var apart, not with the old_dist_info_vars. Then add it to the `input_list` IN THE ORDER that it will be later fed in `optimize_policy` ie on how the list `all_input_values` is constructed.\n",
    "- `optimize_policy`: append to the tuple `all_input_values` the latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting noise.\n",
    "To append noise variables to the input I could do 2 things: \n",
    "- append then to the observations after sampling them in `get_action` and then treating all as expanded observations. Downside: the observations get \"polluted\" and when optimizing, after recoverig `latent` from `agent_infos`, we should construct a new observations to include that noise variables.\n",
    "- keep the latents separate and change `_f_dist` in the policy such that it also takes as input `latent_var`. Then construct the NN to accomodate that. So symbollically combine them. Let's do this last part.\n",
    "Let's list the changes to do:\n",
    "- I add to `get_action` a latent normally sampled (2,).\n",
    "- change `dist_info_sym` to have also as input the latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A-where the dist will depend on latents \n",
    "dist_info_vars = self.policy.dist_info_sym(obs_var, latent_var, action_var)\n",
    "#P-give also the latent to where we compute the output of the NN\n",
    "def dist_info_sym(self, obs_var, latent_var, action_var):\n",
    "    mean_var, log_std_var = L.get_output([self._l_mean, self._l_log_std], obs_var, latent_var)\n",
    "    return dict(mean=mean_var, log_std=log_std_var)\n",
    "##\n",
    "obs_dim = env_spec.observation_space.flat_dim + latent_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check also `old_dist_info_vars`!! I think it's just the one that was sampled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New loss\n",
    "See if we can use the new latents in the surrogate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[[ 0.60336135]\n",
      " [-1.196441  ]\n",
      " [ 0.0301206 ]\n",
      " [ 0.34410733]]\n",
      "[[  0.           1.           2.           0.60336135]\n",
      " [  3.           4.           5.          -1.196441  ]\n",
      " [  6.           7.           8.           0.0301206 ]\n",
      " [  9.          10.          11.           0.34410733]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(12).reshape((4,3))\n",
    "print a\n",
    "b = np.random.randn(4,1)\n",
    "print b\n",
    "c = np.concatenate ((a,b), axis=1)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as TT\n",
    "a = TT.fmatrix('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shape.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array((1.332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "a = -0.00437\n",
    "bucket = np.floor(a/0.01) #this truncates\n",
    "print bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "601\n"
     ]
    }
   ],
   "source": [
    "bound = 3\n",
    "num_bins=600\n",
    "step = (2.*bound)/num_bins\n",
    "print step\n",
    "samples=num_bins*10\n",
    "x = np.arange(-bound,bound+step, step)\n",
    "print len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
