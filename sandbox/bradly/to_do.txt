Third Person:
Collect good samples (images)
Collect bad samples (images)
Confuse domains
Classify samples

Train Policy based on classifier

Test this by collecting experts from both camera angels and failures from both and then
seeing if the domain confusion discriminator can handle it.


Analogy:
Global attractor policy.
Don't have local inverse, so can't do this quite yet.
Resort to pure supervision on the good trajs.
How do I ensure the start and end pt are the same in new envs that are generated?